{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- 정량 평가의 경우 (e.g. acc 80% 이상)은 정확히 해당 지표를 맞추어야 합니다.\n",
    "- 다음의 경우는 **미평가**가 될 수 있습니다.\n",
    "    - **코드만 있고 결과물이 없는 경우**\n",
    "        - **코드에 대한 설명이 없는 경우**\n",
    "        - **회고가 없는 경우**\n",
    "    - **깃헙 링크가 잘못되어 열람이 안되는 경우**\n",
    "        - **(중요) 링크를 제출하기 전에 해당 링크에서 프로젝트가 잘 열리는지 꼭 확인해주세요.**\n",
    "        - 만약 프로젝트의 용량이 커서 프로젝트 로딩이 안된다면 **nbviewer 링크**를 제출해주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d981e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# sklearn라이브러리를 임포트하고 버전 확인하기\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4abcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. import 하기\n",
    "from sklearn.datasets import load_wine                  # sklearn datasets으로 wine 데이터셋 로드\n",
    "from sklearn.model_selection import train_test_split    # 데이터셋을 train, test로 분할\n",
    "\n",
    "from sklearn.metrics import classification_report       # Text summary of the precision, recall, F1 score for each class\n",
    "from sklearn.metrics import accuracy_score              # sklearn.metrincs는 평가에 대한 함수 모음집, 정확도\n",
    "from sklearn.metrics import confusion_matrix            # sklearn.metrincs는 평가에 대한 함수 모음집, 오차행렬\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier         # DecisionTree 분류기\n",
    "from sklearn.ensemble import RandomForestClassifier     # Random forest 분류기\n",
    "from sklearn import svm                                 # SVM 분류기\n",
    "from sklearn.linear_model import SGDClassifier          # SGD 분류기\n",
    "from sklearn.linear_model import LogisticRegression     # Logistic Regression 분류기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b26a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((36, 13), (36,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 데이터 준비하기\n",
    "wines = load_wine()                 # wine 데이터셋의 객체 생성(자료 가져오기)\n",
    "type(wines)                         # type은 Bunch으로 Dictionary 자료형과 유사한 자료형\n",
    "\n",
    "\n",
    "# 3. 데이터 이해하기\n",
    "\n",
    "# 데이터와 타켓 데이터셋 변수에 할당\n",
    "wines_data = wines.data             # wines 데이터셋의 feature 값들을 data 변수에 할당\n",
    "wines_label = wines.target          # wines 데이터셋의 target 값들을 label 변수에 할당\n",
    "\n",
    "# wines 메서드 확인하기\n",
    "dir(wines)                          # wines 메서드 보기\n",
    "wines.keys()                        # wines 메서드 보기 (딕셔너리 형태)\n",
    "\n",
    "# 데이터\n",
    "wines_data                          # wines 데이터셋의 각 데이터(행)을 보기\n",
    "                                    # type은 ndarray(1차원)\n",
    "                                    # data는 머신러닝에 학습시킬 \"문제지\" \n",
    "wines_data.shape                    # nd.ndarray 타입이고, 178개 데이터(세로)가 있으며 13개의 속성값(가로)이 있음\n",
    "wines_data[0]                       # wines.data의 첫번째 데이터(원소) 확인\n",
    "wines_data[0].shape                 # 첫번째 데이터는 13개 속성이 있음\n",
    "\n",
    "# 속성\n",
    "wines.feature_names                 # 속성(Attribute)의 이름\n",
    "                                    # 'pixel_0_0 처럼 0번 데이터의 0번 속성'\n",
    " \n",
    "# Label, Class, Target\n",
    "wines.target                        # wines 데이터셋의 속성값(열) 보기.\n",
    "                                    # type은 ndarray(1차원)\n",
    "                                    # target은 머신러닝 학습에 필요한 \"정답지\"\n",
    "wines.target.shape                  # target 속성은 178개 데이터가 존재\n",
    "wines.target_names                  # label 또는 Class 또는 Target 이름\n",
    "target_names = wines.target_names   # target_names 변수에 할당\n",
    "\n",
    "# 요약 문서 \n",
    "print(wines.DESCR)                  # wines 데이터셋 설명\n",
    "\n",
    "wines.frame                         # ???? NoneType이며\n",
    "\n",
    "\n",
    "# 4. Train, Test로 데이터 분할하기\n",
    "''' 전체 데이터를 모두 학습시키는데 사용하면 테스트용 데이터가 없으므로 데이터의 일부는 테스트용으로 떼어놓는다\n",
    "    digits_data 데이터셋을 X_train, X_test(20%) 떼어두고, digits_label 데이터셋을 y_train, y_test(20%) 떼어 놓는다\n",
    "    \n",
    "    테스트 사이즈 0.2라는 의미는 20%를 떼어 놓겠다는 의미\n",
    "    \n",
    "    random_state는 데이터 분할하기 전에 임의로 돌려서 분할한다는 의미이며 숫자는 램덤 시드값.\n",
    "    train_test_split 인자중 shuffle=True이므로 랜덤 씨드값만 부여하면 됨\n",
    "    사용 이유는 wines.target의 값은 0으로 채우다가 1채우고 2채우는 형식이기 때문에\n",
    "    먄약 랜덤으로 썩지 않고 데이터를 분할하면 앞에서부터 대부분 0과 1의 라벨값만 얻어지고 테스트는 전부 2로 할당받을 것이므로 \n",
    "    데이터 결과의 정확성을 위해 임의로 썩는다\n",
    "    '''\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines_data, wines_label, test_size=0.2, random_state=7)  \n",
    "\n",
    "X_train.shape, y_train.shape    # train 데이터는 전체 데이터의 80% 차지\n",
    "X_test.shape, y_test.shape      # test 데이터는 전체 데이터의 20% 차지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "db7f2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names                                       # 타켓 네임 출력해보기. 악성과 양성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a281601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "       1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-1. DecisionTree 모델 학습\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)     # DecisionTreeClassifier 객체 생성, 랜덤 씨드는 32\n",
    "print(decision_tree._estimator_type)                        # decision_tree 객체 타입은 classifier인 분류기\n",
    "\n",
    "decision_tree.fit(X_train, y_train)                         # train 데이터셋으로 의사결정나무 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)        # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05f3127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "       1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-2. Random Forest 모델 학습\n",
    "random_forest = RandomForestClassifier(random_state=32)  # Random Forest Classifier 객체 생성\n",
    "print(random_forest._estimator_type)                     # random_forest 객체 타입은 classifier인 분류기\n",
    "\n",
    "random_forest.fit(X_train, y_train)                      # train 데이터셋으로 랜덤 포레스트 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_random_forest = random_forest.predict(X_test)     # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "717013e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-3. SVM 모델 학습\n",
    "svm_model = svm.SVC()                                    # SVM Classifier 객체 생성\n",
    "print(svm_model._estimator_type)                         # svm_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "\n",
    "svm_model.fit(X_train, y_train)                          # train 데이터셋으로 svm 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_svm_model = svm_model.predict(X_test)             # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_svm_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c195795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-4. SGD Classifier 모델 학습\n",
    "sgd_model = SGDClassifier()                              # SGD Classifier 객체 생성\n",
    "print(sgd_model._estimator_type)                         # sgd_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "sgd_model.fit(X_train, y_train)                          # train 데이터셋으로 sgd 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)             # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_sgd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35c0309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 1, 2, 1, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 1,\n",
       "       1, 1, 0, 2, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-5. Logistic Regression 모델 학습\n",
    "logistic_model = LogisticRegression(max_iter=10000)      # Logistic Regression 객체 생성\n",
    "print(logistic_model._estimator_type)                    # logistic_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "logistic_model.fit(X_train, y_train)                     # train 데이터셋으로 logistic regression 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)   # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56197816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 분류에 사용되는 척도 종류 및 성능 평가\n",
    "# 척도 종류\n",
    "#    1) accuracy_score\n",
    "#    2) confusion matrix\n",
    "#    3) classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-1 DecisionTree 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe6e20a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-1-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 94%이므로 나쁘지 않다. 테스트 데이터가 약 36개이므로 총 33.8개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e4fe71e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  2, 10]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-1-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_decision_tree)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 94%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 7개중 실제 class 0을 보여주고 올바르게 0이라고 예측한 경우(TP)가 7개 -> 100%\n",
    "# 실제 클래스 1: 총 17개중 실제 class 1을 보여주고 올바르게 1이라고 예측한 경우(TP)가 17개 -> 100 %\n",
    "# 실제 클래스 2: 총 12개중 실제 class 2를 보여주고 올바르게 2이라고 예측한 경우(TP)가 10개, 실제 class 2을 보여줬는데 예측 class 1로 예측한 경우(FN) 2개 -> 83%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 7개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 7 -> 100%\n",
    "# 예측 클래스 1: 총 19개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 17 -> 89%\n",
    "# 예측 클래스 2: 총 10개중 양성 클래스 2에 속한다고 예측한 것 중에서 실제 2인 경우(TP)가 10 -> 100%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Decisiion Tree 모델의 f1-score의 단순평균(Macro)과 가중평균(Weighted)는 0.95와 0.94로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d79f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         7\n",
      "     class_1       0.89      1.00      0.94        17\n",
      "     class_2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-1-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_decision_tree, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f480fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-2. Random Forest 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "75fd8852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-2-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 100%이므로 나쁘지 않다. 테스트 데이터가 약 36개이므로 총 34.6개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58908ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  0, 12]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-2-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_random_forest)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 100%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 7개중 실제 class 0을 보여주고 올바르게 0이라고 예측한 경우(TP)가 7개 -> 100%\n",
    "# 실제 클래스 1: 총 17개중 실제 class 1을 보여주고 올바르게 1이라고 예측한 경우(TP)가 17개 -> 100%\n",
    "# 실제 클래스 2: 총 12개중 실제 class 2를 보여주고 올바르게 2이라고 예측한 경우(TP)가 12개 -> 100%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 7개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 7 -> 100%\n",
    "# 예측 클래스 1: 총 19개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 17 -> 100%\n",
    "# 예측 클래스 2: 총 12개중 양성 클래스 2에 속한다고 예측한 것 중에서 실제 2인 경우(TP)가 12 -> 100%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Random Forest 모델의 f1-score의 단순평균(Macro)과 가중평균는 1.00 으로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2eb3a07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         7\n",
      "     class_1       1.00      1.00      1.00        17\n",
      "     class_2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-2-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_random_forest, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1266d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-3. SVM 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11ae592f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-3-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_svm_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 61%이므로 나쁘다. 테스트 데이터가 약 36개이므로 총 22개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d2d671a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0,  1],\n",
       "       [ 1, 15,  1],\n",
       "       [ 0, 11,  1]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-3-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_svm_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 61%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 7개중 실제 class 0을 보여주고 올바르게 0이라고 예측한 경우(TP)가 6개, 실제 class 0을 보여줬는데 class 2로 예측한 경우(FN) 1개 -> 86%\n",
    "# 실제 클래스 1: 총 17개중 실제 class 1을 보여주고 올바르게 1이라고 예측한 경우(TP)가 15개, \n",
    "#             실제 class 1을 보여줬는데 class 0로 예측한 경우(FN) 1개, 실제 class 1을 보여줬는데 class 2로 예측한 경우(FN) 1개 -> 88%\n",
    "# 실제 클래스 2: 총 12개중 실제 class 2를 보여주고 올바르게 2이라고 예측한 경우(TP)가 1개,\n",
    "#             실제 class 1을 보여줬는데 class 1로 예측한 경우(FN) 11개 -> 8%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 class 2에서 8%로 낮게 나왔다. 이런 경우 f1-score 조화평균값 확인 필요\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 7개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 6 -> 86%\n",
    "# 예측 클래스 1: 총 19개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 15 -> 58%\n",
    "# 예측 클래스 2: 총 12개중 양성 클래스 2에 속한다고 예측한 것 중에서 실제 2인 경우(TP)가 11 -> 33%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 33%으로 낮게 나왔다. 이런 경우 f1-score 조화평균값 확인 필요\n",
    "\n",
    "# 결론\n",
    "# SV 모델의 f1-score의 단순평균(Macro)와 가중평균(Weighted Avg)는 0.56과. 0.54으로 정확도와 차이가 거의 없으며 전체 f1-score 평균이 낮으므로\n",
    "# SVM 학습 모델은 적절치 않다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6cdc901b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.86      0.86      0.86         7\n",
      "     class_1       0.58      0.88      0.70        17\n",
      "     class_2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-3-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_svm_model, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-4. SGD Classifier 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "676c7c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4722222222222222"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-4-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_sgd_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 47.2%이므로 나쁘지 않다. 테스트 데이터가 약 36개이므로 총 34개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5300030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 7, 10,  0],\n",
       "       [11,  1,  0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-4-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_sgd_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 47.2%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 7개중 실제 class 0을 보여주고 올바르게 0이라고 예측한 경우(TP)가 7개 -> 100%\n",
    "# 실제 클래스 1: 총 17개중 실제 class 1을 보여주고 올바르게 1이라고 예측한 경우(TP)가 10개, \n",
    "#             실제 class 1을 보여줬는데 class 0로 예측한 경우(FN) 7개 -> 59%\n",
    "# 실제 클래스 2: 총 12개중 실제 class 2를 보여주고 올바르게 2이라고 예측한 경우(TP)가 0개,\n",
    "#             실제 class 2을 보여줬는데 class 0로 예측한 경우(FN) 11개, 실제 class 2을 보여줬는데 class 1로 예측한 경우(FN) 1개 -> 0%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 class 2에서 0%으로 도출됨. 이런 경우 f1-score 조화평균값으로 더 알아봄\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 25개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 7개 -> 28%\n",
    "# 예측 클래스 1: 총 11개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 10개 -> 91%\n",
    "# 예측 클래스 2: 총 0개중 양성 클래스 2에 속한다고 예측한 것 중에서 실제 2인 경우(TP)가 0개 -> 0%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 class 2에서 낮게 나왔다. 이런 경우 f1-score 조화평균값으로 더 알아봄\n",
    "\n",
    "# 결론\n",
    "# SGD 모델의 f1-score의 단순평균(Macro)과 가중평균(weighted avg)는 0.38과 0.42로 너무 낮다. class 2에서 정밀도와 재현율의 TP가 0이게 되어\n",
    "# 둘 다 0%으로 나왔고 조화평균인 f1-score도 값이 0이 되었다(zerodivision 0이 되므로 인자에서 warning을 수정함)\n",
    "# 따라서 SGD 평가도 사용할 수 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78920a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.28      1.00      0.44         7\n",
      "     class_1       0.91      0.59      0.71        17\n",
      "     class_2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.47        36\n",
      "   macro avg       0.40      0.53      0.38        36\n",
      "weighted avg       0.48      0.47      0.42        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-4-3 classification_reprot 평가\n",
    "print(classification_report(y_test, y_pred_sgd_model, target_names=target_names, zero_division=0))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20b93697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-5. Logistic Regression 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "120c819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-5-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 97.2%이므로 나쁘지 않다. 테스트 데이터가 약 36개이므로 총 35개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "102ae28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0],\n",
       "       [ 0, 17,  0],\n",
       "       [ 0,  1, 11]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-5-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_logistic_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 97.2%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 7개중 실제 class 0을 보여주고 올바르게 0이라고 예측한 경우(TP)가 7개 -> 100%\n",
    "# 실제 클래스 1: 총 17개중 실제 class 1을 보여주고 올바르게 1이라고 예측한 경우(TP)가 17개 -> 100%\n",
    "# 실제 클래스 2: 총 12개중 실제 class 2를 보여주고 올바르게 2이라고 예측한 경우(TP)가 11개,\n",
    "#             실제 class 2을 보여줬는데 class 1로 예측한 경우(FN) 1개 -> 92%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 7개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 7개 -> 100%\n",
    "# 예측 클래스 1: 총 18개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 17개 -> 94%\n",
    "# 예측 클래스 2: 총 11개중 양성 클래스 2에 속한다고 예측한 것 중에서 실제 2인 경우(TP)가 11개 -> 100%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 class 2에서 낮게 나왔다. 이런 경우 f1-score 조화평균값으로 더 알아봄\n",
    "\n",
    "# 결론\n",
    "# Logistic Regression 모델의 f1-score의 단순평균(Macro)과 가중평균(weighted avg)는 0.98과 0.97으로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "022e7d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      1.00      1.00         7\n",
      "     class_1       0.94      1.00      0.97        17\n",
      "     class_2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-5-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_logistic_model, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45503355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 해석\n",
    "# 어떤 모델이 가장 좋은 성능을 보이는가? \n",
    "# -> Random Forest 모델\n",
    "# 모델 성능 평가 지표로 무엇으로 설정하겠는가?\n",
    "# -> Random Forest 모델의 평가가 정확도가 높고 데이터셋의 각 클래스마다 데이터들이 balanced하다. 따라서 정확도만으로도 평가해도 좋지만 추가적으로 오차행렬을\n",
    "#    진행했는데 그중에서 F1-Score 점수가 1.00으로 다른 모델에 비해 가장 높았으므로 최종 모델을 Random Forest으로 선정함\n",
    "# sklearn.metrics에서 제공하는 평가지표 선정하고 선택한 이유?\n",
    "# -> classification_report와 confusion_matrix을 선택했고, 그 이유는 오차행렬을 알면 정확도, 재현율, 정밀도, 가중조화평균, 단순평균, 가중평균을 구할 수 있기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db87f647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. 이번 프로젝트에서 어려웠던 점\\n    앞의 프로젝트와 마찬가지로 데이터를 해석하는데 어려움이 있었다. 또한 SGD 학습 모델 성능 평가에서 class 2의 정밀도와 재현율이 0%가 되어 f1-score\\n    도 0이 되었다. 이 경우 sklearn에서 zerodivision을 0으로 설정해서 에러는 없앴지만 이렇게 하는 것이 맞는지 모르겠다\\n    \\n2. 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\\n    평가 모델의 정확한 의미와 해석하는 방법. 그리고 제로디비전을 처리하는 방법이 맞았는지 모르겠음\\n    \\n3. 루브릭 평가 지표를 맞추기 위해 시도한 것들\\n    이번 평가에는 루브릭 평가가 없었음\\n    \\n4. 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정\\n    이번 평가에는 루브릭 평가가 없었음\\n    \\n5. 자기 다짐\\n    같은 내용 반복이라 처음 데이터 성능 평가보다는 빠르게 했지만 그래도 데이터 해석하고 결론을 도출하는데 이해도가 아직 떨어진다. 조금 더 알아봐야겠다\\n    \\n'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회고\n",
    "\n",
    "'''\n",
    "1. 이번 프로젝트에서 어려웠던 점\n",
    "    앞의 프로젝트와 마찬가지로 데이터를 해석하는데 어려움이 있었다. 또한 SGD 학습 모델 성능 평가에서 class 2의 정밀도와 재현율이 0%가 되어 f1-score\n",
    "    도 0이 되었다. 이 경우 sklearn에서 zerodivision을 0으로 설정해서 에러는 없앴지만 이렇게 하는 것이 맞는지 모르겠다\n",
    "    \n",
    "2. 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "    평가 모델의 정확한 의미와 해석하는 방법. 그리고 제로디비전을 처리하는 방법이 맞았는지 모르겠음\n",
    "    \n",
    "3. 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "   1) wines 데이터셋의 관련 메서드를 모두 출력해보고 속성과 타켓/클래스 이름 등 각각이 무엇을 의미하는지 확인해보았습니다.\n",
    "      feature은 총 13개며 클래스는 class 0 ~ 2까지가 있었습니다\n",
    "   2) 5가지 모델에 전부 학습 시키고 그 결과를 비교하여 최종 모델을 선정하였습니다\n",
    "   3) 평가 지표 선택 이유와 그 근거를 위에 기술함\n",
    "    \n",
    "4. 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정\n",
    "    달성 완료함\n",
    "    \n",
    "5. 자기 다짐\n",
    "    같은 내용 반복이라 처음 데이터 성능 평가보다는 빠르게 했지만 그래도 데이터 해석하고 결론을 도출하는데 이해도가 아직 떨어진다. 조금 더 알아봐야겠다\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc62afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f40910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
