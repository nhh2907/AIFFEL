{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "- 정량 평가의 경우 (e.g. acc 80% 이상)은 정확히 해당 지표를 맞추어야 합니다.\n",
    "- 다음의 경우는 **미평가**가 될 수 있습니다.\n",
    "    - **코드만 있고 결과물이 없는 경우**\n",
    "        - **코드에 대한 설명이 없는 경우**\n",
    "        - **회고가 없는 경우**\n",
    "    - **깃헙 링크가 잘못되어 열람이 안되는 경우**\n",
    "        - **(중요) 링크를 제출하기 전에 해당 링크에서 프로젝트가 잘 열리는지 꼭 확인해주세요.**\n",
    "        - 만약 프로젝트의 용량이 커서 프로젝트 로딩이 안된다면 **nbviewer 링크**를 제출해주세요.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0a723b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# sklearn라이브러리를 임포트하고 버전 확인하기\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2b8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((360, 64), (360,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. import 하기\n",
    "from sklearn.datasets import load_digits                # sklearn datasets으로 digits 데이터셋 로드\n",
    "from sklearn.model_selection import train_test_split    # 데이터셋을 train, test로 분할\n",
    "\n",
    "from sklearn.metrics import classification_report       # Text summary of the precision, recall, F1 score for each class\n",
    "from sklearn.metrics import accuracy_score              # sklearn.metrincs는 평가에 대한 함수 모음집, 정확도\n",
    "from sklearn.metrics import confusion_matrix            # sklearn.metrincs는 평가에 대한 함수 모음집, 오차행렬\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier         # DecisionTree 분류기\n",
    "from sklearn.ensemble import RandomForestClassifier     # Random forest 분류기\n",
    "from sklearn import svm                                 # SVM 분류기\n",
    "from sklearn.linear_model import SGDClassifier          # SGD 분류기\n",
    "from sklearn.linear_model import LogisticRegression     # Logistic Regression 분류기\n",
    "\n",
    "import matplotlib.pyplot as plt                         # matplotlib\n",
    "\n",
    "\n",
    "# 이미지르 현재 화면에 보여주기 위한 코드\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# 2. 데이터 준비하기\n",
    "digits = load_digits()          # digits 데이터셋의 객체 생성(자료 가져오기)\n",
    "\n",
    "\n",
    "# 3. 데이터 이해하기\n",
    "digits_data = digits.data       # digits 데이터셋의 feature값들을 data 변수에 할당\n",
    "digits_label = digits.target    # digits 데이터셋의 target 값들을 label 변수에 할당\n",
    "\n",
    "dir(digits)                     # digits 메서드 보기\n",
    "type(digits)                    # type은 Bunch으로 Dictionary 자료형과 유사한 자료형\n",
    "digits.keys()                   # digits 메서드 보기\n",
    "                                \n",
    "digits_data                     # data는 머신러닝에 학습시킬 \"문제지\"\n",
    "digits_data.shape               # nd.ndarray 타입이고, 1797개 데이터(세로)가 있으며 64개의 속성값(가로)이 있음\n",
    "                                \n",
    "digits_data[0]                  # digits.data의 첫번째 데이터(원소) 확인\n",
    "digits_data[0].shape            # 첫번째 데이터는 64개 픽셀이 있음\n",
    "digits.feature_names            # 속성(Attribute)의 이름\n",
    "                                # 'pixel_0_0 처럼 0번 데이터의 0번 속성'\n",
    "digits.frame                    # ???? NoneType이며\n",
    "digits.images.shape             # 이미지 파일이 1797개 있으며, 하나의 파일은 8x8픽셀이어서 64개의 배열칸을 사용함\n",
    "digits.images                   # type은 numpy.ndarray이고, 1797개 데이터가 존재하면 각 데이터는 64개 픽셀\n",
    "digits.target.shape             # target 속성은 1797개 데이터가 존재\n",
    "digits.target                   # digits 데이터셋의 속성값 보기. type은 ndarray(1차원)\n",
    "                                # target은 머신러닝 학습에 필요한 \"정답지\"\n",
    "digits.target_names             # label 이름(class 이름)\n",
    "                                # 즉 각 클래스 이름\n",
    "target_names = digits.target_names  # 타켓 이름을 변수에 저장\n",
    "print(digits.DESCR)             # digits 데이터셋 설명\n",
    "\n",
    "\n",
    "# 4. Train, Test로 데이터 분할하기\n",
    "''' 전체 데이터를 모두 학습시키는데 사용하면 테스트용 데이터가 없으므로 데이터의 일부는 테스트용으로 떼어놓는다\n",
    "    digits_data 데이터셋을 X_train, X_test(20%) 떼어두고, digits_label 데이터셋을 y_train, y_test(20%) 떼어 놓는다\n",
    "    \n",
    "    테스트 사이즈 0.2라는 의미는 20%를 떼어 놓겠다는 의미\n",
    "    \n",
    "    random_state는 데이터 분할하기 전에 임의로 돌려서 분할한다는 의미이며 숫자는 램덤 시드값.\n",
    "    train_test_split 인자중 shuffle=True이므로 랜덤 씨드값만 부여하면 됨\n",
    "    사용 이유는 digits.target의 값은 0으로 채우다가 1채우고 2채우는 형식이기 때문에\n",
    "    먄약 랜덤으로 썩지 않고 데이터를 분할하면 앞에서부터 대부분 0과 1의 라벨값만 얻어지고 테스트는 전부 2로 할당받을 것이므로 \n",
    "    데이터 결과의 정확성을 위해 임의로 썩는다\n",
    "    '''\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state=7)  \n",
    "\n",
    "X_train.shape, y_train.shape    # train 데이터는 전체 데이터의 80% 차지\n",
    "X_test.shape, y_test.shape      # test 데이터는 전체 데이터의 20% 차지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "572cd4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names                                       # 타켓 네임 출력해보기. 악성과 양성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b3a295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 한 번 그려보기\n",
    "# 데이터 10개를 추출해서 1열인 배열을 8x8로 재형상시킨후 matplotlib.pyplot으로 이미지를 나타냄\n",
    "for i in range(10):\n",
    "    \n",
    "    # subplot의 axis를 2x5 행렬로 설정하고 순회할 때마다 오른쪽으로 한 칸씩 할당\n",
    "    plt.subplot(2, 5, 1+i)  \n",
    "    \n",
    "    # plt.imshow()는 (m,n) 형태의 데이터를 입력으로 받기 때문에\n",
    "    # 데이터셋 내의 1열로 펼쳐진 64개의 데이터를 원래의 이미지 형태인 (8,8)로 복원\n",
    "    plt.imshow(digits_data[i].reshape(8, 8), cmap='gray')  # 색상은 gray(흑백)\n",
    "    \n",
    "    plt.axis('off')  # 축을 보이지 않게 설정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a15c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0405d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 0, 5, 3, 2, 9, 0, 4, 1, 0, 1, 8, 2, 5, 2, 8, 1, 8, 3, 1, 0, 2,\n",
       "       0, 4, 5, 3, 3, 0, 0, 4, 1, 4, 4, 4, 6, 1, 4, 0, 6, 6, 0, 5, 3, 6,\n",
       "       6, 2, 0, 1, 9, 6, 2, 8, 2, 9, 0, 2, 0, 8, 4, 6, 8, 5, 8, 7, 2, 7,\n",
       "       7, 2, 2, 4, 5, 5, 4, 6, 2, 0, 3, 3, 7, 5, 8, 2, 4, 4, 2, 5, 1, 4,\n",
       "       3, 7, 6, 3, 1, 5, 6, 2, 1, 0, 1, 1, 4, 5, 1, 3, 1, 6, 9, 0, 3, 7,\n",
       "       6, 9, 3, 8, 0, 1, 3, 8, 8, 6, 3, 7, 3, 9, 0, 9, 0, 9, 3, 1, 2, 2,\n",
       "       3, 6, 9, 4, 0, 1, 8, 3, 9, 1, 0, 8, 5, 0, 7, 2, 7, 4, 4, 9, 2, 2,\n",
       "       6, 0, 4, 4, 9, 5, 0, 2, 4, 4, 2, 2, 3, 7, 2, 9, 0, 3, 5, 9, 9, 6,\n",
       "       8, 4, 5, 3, 0, 4, 2, 1, 3, 3, 6, 0, 8, 1, 4, 1, 4, 7, 5, 7, 6, 6,\n",
       "       8, 1, 0, 6, 1, 7, 1, 1, 9, 8, 5, 5, 3, 6, 6, 1, 2, 0, 7, 5, 3, 0,\n",
       "       8, 2, 0, 4, 0, 9, 4, 6, 4, 7, 9, 5, 3, 6, 2, 5, 2, 5, 9, 3, 9, 9,\n",
       "       2, 2, 1, 6, 4, 1, 7, 5, 9, 8, 9, 5, 7, 4, 3, 7, 4, 8, 2, 8, 9, 5,\n",
       "       3, 2, 1, 0, 4, 2, 1, 0, 1, 4, 1, 7, 6, 4, 7, 7, 9, 8, 3, 8, 4, 3,\n",
       "       5, 9, 4, 4, 8, 1, 8, 7, 2, 3, 2, 1, 1, 0, 2, 8, 0, 7, 4, 3, 1, 0,\n",
       "       2, 3, 9, 9, 8, 5, 6, 2, 2, 6, 5, 0, 8, 9, 8, 9, 0, 0, 4, 7, 4, 1,\n",
       "       9, 6, 7, 3, 7, 4, 0, 2, 1, 7, 6, 5, 3, 2, 3, 5, 7, 1, 4, 1, 3, 3,\n",
       "       8, 8, 1, 0, 1, 9, 8, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-1. DecisionTree 모델 학습\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)     # DecisionTreeClassifier 객체 생성, 랜덤 씨드는 32\n",
    "print(decision_tree._estimator_type)                        # decision_tree 객체 타입은 classifier인 분류기\n",
    "\n",
    "decision_tree.fit(X_train, y_train)                         # train 데이터셋으로 의사결정나무 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)        # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c54c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 0, 5, 9, 2, 9, 0, 4, 1, 0, 1, 8, 2, 5, 2, 8, 1, 8, 5, 1, 0, 2,\n",
       "       0, 4, 5, 3, 3, 0, 0, 4, 1, 4, 4, 4, 6, 1, 4, 0, 6, 6, 0, 9, 3, 6,\n",
       "       6, 2, 0, 1, 9, 6, 2, 8, 5, 9, 0, 2, 0, 8, 4, 6, 8, 5, 8, 7, 8, 7,\n",
       "       7, 4, 1, 4, 5, 5, 4, 6, 2, 0, 1, 3, 7, 5, 8, 2, 4, 4, 2, 5, 1, 9,\n",
       "       3, 7, 6, 3, 3, 5, 6, 2, 1, 0, 1, 9, 4, 1, 1, 3, 1, 6, 9, 0, 3, 7,\n",
       "       6, 9, 3, 8, 0, 1, 3, 8, 8, 6, 3, 7, 3, 9, 0, 3, 0, 9, 1, 1, 2, 2,\n",
       "       3, 6, 9, 4, 0, 5, 4, 2, 9, 1, 0, 2, 5, 0, 2, 2, 7, 4, 4, 9, 8, 2,\n",
       "       6, 0, 4, 4, 5, 5, 0, 2, 4, 6, 8, 2, 3, 7, 2, 9, 0, 3, 5, 9, 1, 6,\n",
       "       8, 7, 5, 3, 0, 4, 2, 1, 3, 3, 6, 0, 2, 8, 4, 1, 4, 7, 5, 7, 6, 6,\n",
       "       8, 1, 0, 6, 1, 7, 1, 1, 9, 8, 5, 9, 3, 6, 8, 1, 2, 0, 7, 5, 3, 0,\n",
       "       8, 2, 0, 4, 0, 9, 4, 8, 4, 7, 9, 7, 3, 6, 2, 5, 1, 5, 9, 2, 9, 9,\n",
       "       7, 2, 1, 6, 7, 1, 7, 5, 7, 8, 9, 5, 7, 4, 3, 7, 7, 8, 2, 8, 9, 5,\n",
       "       3, 2, 8, 0, 4, 2, 1, 0, 8, 4, 1, 7, 1, 4, 7, 7, 1, 8, 3, 8, 4, 3,\n",
       "       5, 9, 4, 4, 8, 1, 8, 7, 2, 3, 1, 1, 1, 0, 2, 8, 0, 7, 4, 4, 1, 0,\n",
       "       2, 3, 9, 9, 8, 5, 4, 2, 2, 6, 5, 0, 8, 9, 8, 9, 0, 0, 9, 7, 4, 1,\n",
       "       2, 6, 7, 3, 7, 4, 0, 2, 1, 7, 2, 5, 7, 2, 3, 5, 7, 1, 4, 1, 3, 3,\n",
       "       8, 8, 1, 0, 1, 9, 3, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-2. Random Forest 모델 학습\n",
    "random_forest = RandomForestClassifier(random_state=32)  # Random Forest Classifier 객체 생성\n",
    "print(random_forest._estimator_type)                     # random_forest 객체 타입은 classifier인 분류기\n",
    "\n",
    "random_forest.fit(X_train, y_train)                      # train 데이터셋으로 랜덤 포레스트 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_random_forest = random_forest.predict(X_test)     # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49fb849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 0, 5, 9, 2, 9, 0, 4, 1, 0, 1, 8, 2, 5, 2, 8, 1, 8, 9, 1, 0, 2,\n",
       "       0, 4, 5, 3, 3, 0, 0, 4, 1, 4, 4, 4, 6, 1, 4, 0, 6, 6, 0, 9, 3, 6,\n",
       "       6, 2, 0, 1, 9, 6, 2, 8, 5, 9, 0, 2, 0, 8, 4, 6, 8, 5, 8, 7, 8, 7,\n",
       "       7, 4, 1, 4, 5, 5, 4, 6, 2, 0, 1, 3, 7, 5, 8, 2, 4, 4, 2, 5, 1, 9,\n",
       "       3, 7, 6, 3, 3, 5, 6, 2, 1, 0, 1, 9, 4, 1, 1, 3, 1, 6, 9, 0, 3, 7,\n",
       "       6, 9, 3, 8, 0, 1, 3, 8, 8, 6, 3, 7, 3, 9, 0, 3, 0, 9, 1, 1, 2, 2,\n",
       "       3, 6, 9, 4, 0, 5, 4, 2, 9, 1, 0, 2, 5, 0, 2, 2, 7, 4, 6, 9, 8, 2,\n",
       "       6, 0, 4, 4, 5, 5, 0, 2, 4, 6, 8, 2, 3, 7, 2, 9, 0, 3, 5, 9, 1, 6,\n",
       "       8, 7, 5, 3, 0, 4, 2, 1, 3, 3, 6, 0, 2, 8, 4, 1, 4, 7, 5, 7, 6, 6,\n",
       "       8, 1, 0, 6, 8, 7, 1, 1, 9, 8, 5, 5, 3, 6, 8, 1, 2, 0, 7, 5, 3, 0,\n",
       "       8, 2, 0, 4, 0, 9, 4, 8, 4, 7, 9, 7, 3, 6, 2, 5, 1, 5, 9, 2, 9, 9,\n",
       "       8, 2, 1, 6, 7, 1, 7, 5, 7, 8, 9, 5, 7, 4, 3, 7, 8, 8, 2, 8, 9, 5,\n",
       "       3, 2, 8, 0, 4, 2, 1, 0, 8, 4, 1, 7, 1, 4, 7, 7, 1, 8, 3, 8, 4, 3,\n",
       "       5, 9, 4, 4, 8, 1, 8, 7, 2, 3, 1, 1, 1, 0, 2, 8, 0, 7, 4, 0, 1, 0,\n",
       "       2, 3, 7, 9, 8, 5, 8, 2, 2, 6, 5, 0, 8, 9, 8, 9, 0, 0, 9, 7, 4, 1,\n",
       "       2, 6, 7, 3, 7, 4, 0, 2, 1, 7, 2, 5, 7, 2, 3, 5, 7, 1, 4, 1, 3, 3,\n",
       "       8, 8, 1, 0, 1, 9, 3, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-3. SVM 모델 학습\n",
    "svm_model = svm.SVC()                             # SVM Classifier 객체 생성\n",
    "print(svm_model._estimator_type)                  # svm_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "\n",
    "svm_model.fit(X_train, y_train)                   # train 데이터셋으로 svm 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_svm_model = svm_model.predict(X_test)      # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8886af01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 0, 5, 3, 2, 9, 0, 4, 1, 7, 1, 8, 2, 5, 2, 8, 1, 8, 5, 1, 0, 2,\n",
       "       0, 4, 5, 3, 3, 0, 0, 4, 1, 4, 4, 4, 6, 1, 4, 0, 6, 6, 0, 5, 3, 6,\n",
       "       6, 2, 0, 1, 9, 6, 2, 8, 5, 9, 0, 2, 0, 8, 4, 6, 1, 5, 8, 7, 8, 7,\n",
       "       7, 4, 1, 4, 5, 5, 6, 6, 2, 0, 3, 3, 7, 5, 8, 2, 4, 4, 2, 5, 1, 9,\n",
       "       3, 7, 6, 3, 7, 5, 6, 2, 1, 0, 1, 1, 4, 1, 9, 3, 3, 6, 9, 0, 3, 7,\n",
       "       6, 9, 3, 8, 0, 1, 3, 1, 8, 6, 3, 7, 3, 9, 0, 3, 0, 9, 1, 1, 2, 2,\n",
       "       3, 6, 9, 4, 0, 5, 4, 3, 9, 1, 0, 2, 5, 0, 2, 2, 7, 4, 8, 9, 8, 2,\n",
       "       6, 0, 4, 4, 5, 5, 0, 2, 4, 1, 2, 2, 3, 7, 2, 9, 0, 3, 5, 9, 1, 6,\n",
       "       8, 7, 5, 3, 0, 4, 2, 1, 3, 3, 6, 0, 2, 8, 4, 1, 4, 7, 5, 7, 6, 6,\n",
       "       8, 1, 0, 6, 1, 7, 1, 1, 9, 7, 5, 5, 3, 6, 3, 1, 2, 0, 7, 5, 3, 0,\n",
       "       8, 2, 0, 4, 0, 9, 4, 8, 4, 7, 9, 7, 3, 6, 2, 5, 1, 5, 9, 2, 9, 9,\n",
       "       7, 2, 1, 6, 7, 5, 7, 5, 7, 5, 9, 5, 7, 4, 3, 7, 5, 8, 2, 8, 9, 5,\n",
       "       3, 2, 8, 0, 4, 2, 1, 0, 1, 4, 1, 7, 1, 4, 7, 7, 1, 8, 3, 8, 4, 3,\n",
       "       5, 9, 4, 4, 8, 1, 8, 7, 2, 3, 1, 1, 1, 0, 2, 8, 0, 7, 4, 0, 1, 0,\n",
       "       2, 3, 9, 8, 8, 5, 4, 2, 2, 6, 5, 0, 5, 9, 8, 9, 0, 0, 5, 7, 4, 1,\n",
       "       2, 6, 7, 3, 7, 4, 0, 2, 1, 7, 2, 5, 7, 2, 3, 5, 7, 1, 4, 1, 3, 3,\n",
       "       8, 8, 1, 0, 1, 9, 3, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-4. SGD Classifier 모델 학습\n",
    "sgd_model = SGDClassifier()                         # SGD Classifier 객체 생성\n",
    "print(sgd_model._estimator_type)                    # sgd_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "sgd_model.fit(X_train, y_train)                     # train 데이터셋으로 sgd 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)        # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_sgd_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f71a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 0, 5, 3, 2, 9, 0, 4, 1, 0, 1, 8, 2, 5, 2, 5, 1, 8, 5, 1, 0, 2,\n",
       "       0, 4, 5, 3, 3, 0, 0, 4, 1, 4, 4, 4, 6, 1, 4, 0, 6, 6, 0, 9, 3, 6,\n",
       "       6, 2, 0, 1, 9, 6, 2, 8, 5, 9, 0, 2, 0, 8, 4, 6, 8, 5, 8, 7, 8, 7,\n",
       "       7, 4, 1, 4, 5, 5, 4, 6, 2, 0, 1, 3, 7, 5, 8, 2, 4, 4, 2, 5, 1, 9,\n",
       "       3, 7, 6, 3, 7, 5, 6, 2, 1, 0, 1, 9, 4, 1, 9, 3, 1, 6, 9, 0, 3, 7,\n",
       "       6, 9, 3, 8, 0, 1, 3, 8, 8, 6, 3, 7, 3, 9, 0, 3, 0, 9, 1, 1, 2, 2,\n",
       "       3, 6, 9, 4, 0, 5, 4, 2, 9, 1, 0, 2, 5, 0, 2, 2, 7, 4, 8, 9, 8, 2,\n",
       "       6, 0, 4, 4, 5, 5, 0, 2, 4, 6, 2, 2, 3, 7, 2, 9, 0, 3, 5, 9, 1, 6,\n",
       "       8, 7, 5, 3, 0, 4, 2, 1, 3, 3, 6, 0, 2, 8, 4, 1, 4, 7, 5, 7, 6, 6,\n",
       "       8, 1, 0, 6, 8, 7, 1, 1, 9, 8, 5, 5, 3, 6, 8, 1, 2, 0, 7, 5, 3, 0,\n",
       "       8, 2, 0, 4, 0, 9, 4, 8, 4, 7, 9, 7, 3, 6, 2, 8, 1, 5, 9, 2, 9, 9,\n",
       "       7, 2, 1, 6, 7, 8, 7, 5, 7, 8, 5, 5, 7, 4, 3, 7, 5, 8, 2, 8, 9, 5,\n",
       "       3, 2, 8, 0, 4, 2, 1, 0, 8, 4, 1, 7, 1, 4, 7, 7, 1, 8, 3, 8, 4, 3,\n",
       "       5, 9, 4, 4, 8, 1, 8, 7, 2, 3, 1, 1, 1, 0, 2, 8, 0, 7, 4, 0, 1, 0,\n",
       "       2, 3, 3, 9, 8, 5, 8, 2, 2, 6, 5, 0, 5, 9, 8, 9, 0, 0, 9, 7, 4, 1,\n",
       "       2, 6, 7, 3, 7, 4, 0, 2, 1, 7, 2, 5, 7, 2, 3, 5, 7, 1, 4, 1, 3, 3,\n",
       "       8, 8, 1, 0, 1, 9, 3, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5-5. Logistic Regression 모델 학습\n",
    "logistic_model = LogisticRegression(max_iter=10000)     # Logistic Regression 객체 생성\n",
    "print(logistic_model._estimator_type)                   # logistic_model 객체 타입은 classifier인 분류기\n",
    "\n",
    "logistic_model.fit(X_train, y_train)                    # train 데이터셋으로 logistic regression 모델 지도학습(fitting)\n",
    "\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)  # 학습된 모델에 테스트 feature데이터 넣어서 예측값 생성\n",
    "y_pred_logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c32c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 분류에 사용되는 척도 종류 및 성능 평가\n",
    "# 척도 종류\n",
    "#    1) accuracy_score\n",
    "#    2) confusion matrix\n",
    "#    3) classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-1 DecisionTree 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b128ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8555555555555555"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-1-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 85.5%이므로 나쁘지 않다. 테스트 데이터가 약 360개이므로 총 307.8개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b088620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 34,  3,  1,  0,  1,  1,  0,  0,  2],\n",
       "       [ 0,  0, 33,  2,  0,  0,  1,  1,  2,  1],\n",
       "       [ 0,  1,  0, 31,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0,  1,  0, 35,  0,  0,  0,  1,  0],\n",
       "       [ 0,  1,  0,  0,  0, 27,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  2,  0, 26,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  2,  1,  0, 27,  0,  2],\n",
       "       [ 0,  5,  4,  1,  1,  0,  3,  0, 28,  1],\n",
       "       [ 0,  1,  1,  2,  2,  1,  0,  0,  0, 25]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-1-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_decision_tree)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 85.5%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 43개중 실제 0 이미지를 보여주고 올바르게 0이라고 예측한 경우(TP)가 42개, 실제 0을 보여줬는데 3으로 예측한 경우(FN) 1개 -> 98%\n",
    "# 실제 클래스 1: 총 42개중 실제 1 이미지를 보여주고 올바르게 1이라고 예측한 경우(TP)가 34개, 실제 1을 보여줬는데 2로 예측한 경우(FN) 3개,\n",
    "#             실제 1을 보여줬는데 3로 예측한 경우(FN) 1개, ... 실제 1을 보여줬는데 9로 예측한 경우(FN) 2개 -> 0.81 %\n",
    "# 실제 클래스 2: 총 40개중 실제 2 이미지를 보여주고 올바르게 2이라고 예측한 경우(TP)가 33개, 실제 2을 보여줬는데 3으로 예측한 경우(FN) 2개 -> 82%\n",
    "# ...\n",
    "# 실제 클래스 9: 총 32개중 실제 9 이미지를 보여주고 올바르게 9이라고 예측한 경우(TP)가 25개, 실제 9을 보여줬는데 1으로 예측한 경우(FN) 1개 -> 78%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 42개중 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 42 -> 100%\n",
    "# 예측 클래스 1: 총 42개중 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 34 -> 80.95%\n",
    "# ...\n",
    "# 예측 클래스 9: 총 35개중 양성 클래스 9에 속한다고 예측한 것 중에서 실제 9인 경우(TP)가 25 -> 78.1%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Decisiion Tree 모델의 f1-score의 단순평균(Macro)과 가중평균(Weighted)는 0.86으로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cae54cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-1-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247889bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-2. Random Forest 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be7910c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638888888888889"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-2-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_random_forest)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 96.3%이므로 나쁘지 않다. 테스트 데이터가 약 360개이므로 총 346.68개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad5a8c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 27,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  1,  0, 27,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 32,  0,  1],\n",
       "       [ 0,  3,  0,  0,  1,  1,  0,  2, 36,  0],\n",
       "       [ 0,  0,  0,  0,  0,  2,  0,  0,  0, 30]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-2-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_random_forest)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 96.4%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 43개중 실제 0 이미지를 보여주고 올바르게 0이라고 예측한 경우(TP)가 42개, 실제 0을 보여줬는데 3으로 예측한 경우(FN) 1개 -> 98%\n",
    "# 실제 클래스 1: 총 42개중 실제 1 이미지를 보여주고 올바르게 1이라고 예측한 경우(TP)가 42개 -> 100%\n",
    "# 실제 클래스 2: 총 40개중 실제 2 이미지를 보여주고 올바르게 2이라고 예측한 경우(TP)가 40개 -> 100%\n",
    "# ...\n",
    "# 실제 클래스 9: 총 32개중 실제 9 이미지를 보여주고 올바르게 9이라고 예측한 경우(TP)가 30개, 실제 9을 보여줬는데 5으로 예측한 경우(FN) 2개 -> 94%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 42개중 실제 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 42 -> 100%\n",
    "# 예측 클래스 1: 총 45개중 실제 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 42 -> 93%\n",
    "# ...\n",
    "# 예측 클래스 9: 총 32개중 실제 양성 클래스 9에 속한다고 예측한 것 중에서 실제 9인 경우(TP)가 30 -> 94%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Random Forest 모델의 f1-score의 단순평균(Macro)과 가중평균는 0.96으로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "830614b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.98      0.99        43\n",
      "     class 1       0.93      1.00      0.97        42\n",
      "     class 2       1.00      1.00      1.00        40\n",
      "     class 3       1.00      1.00      1.00        34\n",
      "     class 4       0.93      1.00      0.96        37\n",
      "     class 5       0.90      0.96      0.93        28\n",
      "     class 6       1.00      0.96      0.98        28\n",
      "     class 7       0.94      0.97      0.96        33\n",
      "     class 8       1.00      0.84      0.91        43\n",
      "     class 9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-2-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_random_forest, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-3. SVM 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b79c118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-3-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_svm_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 98.8%이므로 나쁘지 않다. 테스트 데이터가 약 360개이므로 총 355.7개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9c26c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 42,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 34,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 28,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 33,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  1,  0,  0, 40,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0, 31]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-3-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_svm_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 98.8%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 43개중 실제 0 이미지를 보여주고 올바르게 0이라고 예측한 경우(TP)가 43개 -> 100%\n",
    "# 실제 클래스 1: 총 42개중 실제 1 이미지를 보여주고 올바르게 1이라고 예측한 경우(TP)가 42개 -> 100%\n",
    "# 실제 클래스 2: 총 40개중 실제 2 이미지를 보여주고 올바르게 2이라고 예측한 경우(TP)가 40개 -> 100%\n",
    "# ...\n",
    "# 실제 클래스 9: 총 32개중 실제 9 이미지를 보여주고 올바르게 9이라고 예측한 경우(TP)가 31개, 실제 9을 보여줬는데 5으로 예측한 경우(FN) 1개 -> 97%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 43개중 실제 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 43 -> 100%\n",
    "# 예측 클래스 1: 총 44개중 실제 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 42 -> 95%\n",
    "# ...\n",
    "# 예측 클래스 9: 총 31개중 실제 양성 클래스 9에 속한다고 예측한 것 중에서 실제 9인 경우(TP)가 31 -> 100%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# SV 모델의 f1-score의 단순평균(Macro)와 가중평균(Weighted Avg)는 0.99으로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3236e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        43\n",
      "     class 1       0.95      1.00      0.98        42\n",
      "     class 2       1.00      1.00      1.00        40\n",
      "     class 3       1.00      1.00      1.00        34\n",
      "     class 4       1.00      1.00      1.00        37\n",
      "     class 5       0.93      1.00      0.97        28\n",
      "     class 6       1.00      1.00      1.00        28\n",
      "     class 7       1.00      1.00      1.00        33\n",
      "     class 8       1.00      0.93      0.96        43\n",
      "     class 9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-3-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_svm_model, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13389a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-4. SGD Classifier 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f45a9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-4-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_sgd_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 94.4%이므로 나쁘지 않다. 테스트 데이터가 약 360개이므로 총 339.8개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dae0d7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 35,  0,  3,  0,  0,  0,  0,  3,  1],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 32,  0,  0,  0,  0,  2,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0, 26,  0,  1,  0],\n",
       "       [ 0,  0,  0,  1,  1,  0,  0, 31,  0,  0],\n",
       "       [ 0,  3,  0,  0,  0,  0,  0,  0, 40,  0],\n",
       "       [ 0,  2,  0,  0,  0,  1,  0,  0,  1, 28]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-4-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_sgd_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 94.4%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 43개중 실제 0 이미지를 보여주고 올바르게 0이라고 예측한 경우(TP)가 43개 -> 100%\n",
    "# 실제 클래스 1: 총 42개중 실제 1 이미지를 보여주고 올바르게 1이라고 예측한 경우(TP)가 35개 -> 95%\n",
    "# 실제 클래스 2: 총 40개중 실제 2 이미지를 보여주고 올바르게 2이라고 예측한 경우(TP)가 40개 -> 100%\n",
    "# ...\n",
    "# 실제 클래스 9: 총 32개중 실제 9 이미지를 보여주고 올바르게 9이라고 예측한 경우(TP)가 28개, 실제 9을 보여줬는데 1로 예측한 경우(FN) 2개 -> 88%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 43개중 실제 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 43 -> 100%\n",
    "# 예측 클래스 1: 총 41개중 실제 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 41 -> 87%\n",
    "# ...\n",
    "# 예측 클래스 9: 총 29개중 실제 양성 클래스 9에 속한다고 예측한 것 중에서 실제 9인 경우(TP)가 28 -> 83%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# SGD 모델의 f1-score의 단순평균(Macro)과 가중평균(weighted avg)는 0.95으로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da00be3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        43\n",
      "     class 1       0.85      0.83      0.84        42\n",
      "     class 2       1.00      1.00      1.00        40\n",
      "     class 3       0.89      0.94      0.91        34\n",
      "     class 4       0.97      1.00      0.99        37\n",
      "     class 5       0.97      1.00      0.98        28\n",
      "     class 6       1.00      0.93      0.96        28\n",
      "     class 7       1.00      0.94      0.97        33\n",
      "     class 8       0.85      0.93      0.89        43\n",
      "     class 9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.95      0.94      0.95       360\n",
      "weighted avg       0.95      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-4-3 classification_reprot 평가\n",
    "print(classification_report(y_test, y_pred_sgd_model, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5946888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-5. Logistic Regression 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9bc2f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9527777777777777"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-5-1 Accuracy 평가\n",
    "# 실제 정답 y_test과 예측값 y_pred 비교하여 정확도 측정하기\n",
    "accuracy = accuracy_score(y_test, y_pred_logistic_model)\n",
    "accuracy\n",
    "\n",
    "# 결과 해석 : \n",
    "# Accuracy가 95.3%이므로 나쁘지 않다. 테스트 데이터가 약 360개이므로 총 343.1개 맞았다는 의미\n",
    "# 단, 정확도는 데이터가 imbalanced이면 결과값의 신뢰도는 떨어진다. 따라서 오차 행렬도 같이 알아보겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5ce009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 40,  0,  0,  0,  0,  0,  0,  1,  1],\n",
       "       [ 0,  0, 40,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 33,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 27,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 27,  0,  1,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0, 32,  0,  0],\n",
       "       [ 0,  2,  1,  0,  1,  4,  0,  0, 35,  0],\n",
       "       [ 0,  0,  0,  1,  0,  2,  0,  0,  0, 29]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6-5-2 confusion matrix 평가\n",
    "confusion_matrix(y_test, y_pred_logistic_model)\n",
    "\n",
    "# 오차 행렬 해석\n",
    "\n",
    "# Accuracy\n",
    "# 전체 예측한 데이터 중에서 실제로 예측이 맞은 것(TP + TN)의 비율\n",
    "# 위의 결과에 따라 95.3%\n",
    "# 그러나 실제 클래스 별 표본의 개수가 서로 차이가 많이 나서 imbalanced한 데이터셋이므로 Accuracy의 결과값은 신뢰성이 없을 수 있으므로 F1-score 값을 확인해야 한다\n",
    "# F1-Score을 알려면 정확도와 재현율을 알아야 함\n",
    "\n",
    "# Recall\n",
    "# 실제 클래스 0: 총 43개중 실제 0 이미지를 보여주고 올바르게 0이라고 예측한 경우(TP)가 43개 -> 100%\n",
    "# 실제 클래스 1: 총 42개중 실제 1 이미지를 보여주고 올바르게 1이라고 예측한 경우(TP)가 40개 -> 95%\n",
    "# 실제 클래스 2: 총 40개중 실제 2 이미지를 보여주고 올바르게 2이라고 예측한 경우(TP)가 40개 -> 99%\n",
    "# ...\n",
    "# 실제 클래스 9: 총 32개중 실제 9 이미지를 보여주고 올바르게 9이라고 예측한 경우(TP)가 29개, 실제 9을 보여줬는데 3로 예측한 경우(FN) 1개... -> 94%\n",
    "# 즉, 실제 각 양성클래스 중에서 제대로 양성이라고 예측한 것의 비율이 높다(재현율이 높다)\n",
    "\n",
    "# Precision\n",
    "# 예측 클래스 0: 총 43개중 실제 양성 클래스 0에 속한다고 예측한 것 중에서 실제 0인 경우(TP)가 43 -> 100%\n",
    "# 예측 클래스 1: 총 41개중 실제 양성 클래스 1에 속한다고 예측한 것 중에서 실제 1인 경우(TP)가 42 -> 95%\n",
    "# ...\n",
    "# 예측 클래스 9: 총 29개중 실제 양성 클래스 9에 속한다고 예측한 것 중에서 실제 9인 경우(TP)가 30 -> 97%\n",
    "# 즉, 예측한 것 중에서 실제 양성으로 예측한 수의 비율이 높다(정확도가 높다)\n",
    "\n",
    "# 결론\n",
    "# Logistic Regression 모델의 f1-score의 단순평균(Macro)과 가중평균(weighted avg)는 0.95으로 정확도와 차이가 거의 없다.\n",
    "# Accuracy도 괜찮고 F1-score도 괜찮다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b27f204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        43\n",
      "     class 1       0.95      0.95      0.95        42\n",
      "     class 2       0.98      1.00      0.99        40\n",
      "     class 3       0.94      0.97      0.96        34\n",
      "     class 4       1.00      1.00      1.00        37\n",
      "     class 5       0.79      0.96      0.87        28\n",
      "     class 6       1.00      0.96      0.98        28\n",
      "     class 7       0.94      0.97      0.96        33\n",
      "     class 8       0.92      0.81      0.86        43\n",
      "     class 9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6-5-3 classification_report 평가\n",
    "print(classification_report(y_test, y_pred_logistic_model, target_names=target_names))\n",
    "\n",
    "# 오차 행렬의 요약 버전\n",
    "# 이미 위에서 설명했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 결과 해석\n",
    "# 어떤 모델이 가장 좋은 성능을 보이는가? SVM 모델\n",
    "# 모델 성능 평가 지표로 무엇으로 설정하겠는가?\n",
    "# -> SVM 모델의 평가가 정확도가 높고 데이터셋의 각 클래스마다 데이터들이 balanced하다. 따라서 정확도만으로도 평가해도 좋지만 추가적으로 오차행렬을\n",
    "#    진행했는데 그중에서 F1-Score 점수가 다른 모델에 비해 가장 높았으므로 최종 모델을 SVM으로 선정함\n",
    "# sklearn.metrics에서 제공하는 평가지표 선정하고 선택한 이유?\n",
    "# -> classification_report와 confusion_matrix을 선택했고, 그 이유는 오차행렬을 알면 정확도, 재현율, 정밀도, 가중조화평균, 단순평균, 가중평균을 구할 수 있기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56be80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회고\n",
    "\n",
    "'''\n",
    "1. 이번 프로젝트에서 어려웠던 점\n",
    "    다양한 용어가 있었고 그에 대한 의미를 파악하지 못하였던 것이 어려웠습니다. 특히 평가 결과를 해석하는 법이 익숙치 않으며 정확하게 해석하는\n",
    "    방법을 몰랐고, 코드 구현도 중요하지만 해석하는 데이터를 해석하는 능력이 무엇보다 중요함을 알게됐습니다\n",
    "    \n",
    "2. 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "    평가 모델의 정확한 의미와 해석하는 방법. 인터넷과 유튜브로 찾아보면서 완성했지만 100% 이해하지는 못하였음\n",
    "    \n",
    "3. 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "   1) digits 데이터셋의 관련 메서드를 모두 출력해보고 속성과 타켓/클래스 이름 등 각각이 무엇을 의미하는지 확인해보았습니다.\n",
    "      feature은 총 64개며 클래스는 숫자 0부터 9까지 총 10가지가 있었습니다\n",
    "   2) 5가지 모델에 전부 학습 시키고 그 결과를 비교하여 최종 모델을 선정하였습니다\n",
    "   3) 평가 지표 선택 이유와 그 근거를 위에 기술함\n",
    "\n",
    "4. 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정\n",
    "    달성 완료함\n",
    "    \n",
    "5. 자기 다짐\n",
    "    용어가 어려웠고 그 용어를 이해하는데 시간을 많이 소비했습니다. 그럼에도 불구하고 제대로 파악이 안되고 있다는 점에서 부족한 부분은 시간이\n",
    "    날 때 계속해서 보완해야겠습니다\n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
